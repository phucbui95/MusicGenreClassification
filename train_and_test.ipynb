{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %load compact_cnn/models.py\n",
    "# 2016-06-06 Updating for Keras 1.0 API\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from argparse import Namespace\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Layer, Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "\n",
    "SR = 12000\n",
    "\n",
    "\n",
    "def build_convnet_model(args, last_layer=True, sr=None, compile=True):\n",
    "    ''' '''\n",
    "    tf = args.tf_type\n",
    "    normalize = args.normalize\n",
    "    if normalize in ('no', 'False'):\n",
    "        normalize = None\n",
    "    decibel = args.decibel\n",
    "    model = raw_vgg(args, tf=tf, normalize=normalize, decibel=decibel,\n",
    "                    last_layer=last_layer, sr=sr)\n",
    "    if compile:\n",
    "        model.compile(optimizer=keras.optimizers.Adam(lr=5e-3),\n",
    "                      loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "def raw_vgg(args, input_length=12000 * 29, tf='melgram', normalize=None,\n",
    "            decibel=False, last_layer=True, sr=None):\n",
    "    ''' when length = 12000*29 and 512/256 dft/hop, \n",
    "    melgram size: (n_mels, 1360)\n",
    "    '''\n",
    "    assert tf in ('stft', 'melgram')\n",
    "    assert normalize in (None, False, 'no', 0, 0.0, 'batch', 'data_sample', 'time', 'freq', 'channel')\n",
    "    assert isinstance(decibel, bool)\n",
    "\n",
    "    if sr is None:\n",
    "        sr = SR  # assumes 12000\n",
    "\n",
    "    conv_until = args.conv_until\n",
    "    trainable_kernel = args.trainable_kernel\n",
    "    model = Sequential()\n",
    "    # decode args\n",
    "    fmin = args.fmin\n",
    "    fmax = args.fmax\n",
    "    if fmax == 0.0:\n",
    "        fmax = sr / 2\n",
    "    n_mels = args.n_mels\n",
    "    trainable_fb = args.trainable_fb\n",
    "    model.add(Melspectrogram(n_dft=512, n_hop=256, power_melgram=2.0,\n",
    "                             input_shape=(1, input_length),\n",
    "                             trainable_kernel=trainable_kernel,\n",
    "                             trainable_fb=trainable_fb,\n",
    "                             return_decibel_melgram=decibel,\n",
    "                             sr=sr, n_mels=n_mels,\n",
    "                             fmin=fmin, fmax=fmax,\n",
    "                             name='melgram'))\n",
    "\n",
    "    poolings = [(2, 4), (3, 4), (2, 5), (2, 4), (4, 4)]\n",
    "\n",
    "    if normalize in ('batch', 'data_sample', 'time', 'freq', 'channel'):\n",
    "        model.add(Normalization2D(normalize))\n",
    "    model.add(get_convBNeluMPdrop(5, [32, 32, 32, 32, 32],\n",
    "                                  [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3)],\n",
    "                                  poolings, model.output_shape[1:], conv_until=conv_until))\n",
    "    if conv_until != 4:\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "    else:\n",
    "        model.add(Flatten())\n",
    "\n",
    "    if last_layer:\n",
    "        model.add(Dense(50, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_convBNeluMPdrop(num_conv_layers, nums_feat_maps,\n",
    "                        conv_sizes, pool_sizes, input_shape, conv_until=None):\n",
    "    # [Convolutional Layers]\n",
    "    model = Sequential(name='ConvBNEluDr')\n",
    "    input_shape_specified = False\n",
    "\n",
    "    if conv_until is None:\n",
    "        conv_until = num_conv_layers  # end-inclusive.\n",
    "\n",
    "    for conv_idx in xrange(num_conv_layers):\n",
    "        # add conv layer\n",
    "        if not input_shape_specified:\n",
    "            model.add(Convolution2D(nums_feat_maps[conv_idx],\n",
    "                                    conv_sizes[conv_idx][0], conv_sizes[conv_idx][1],\n",
    "                                    input_shape=input_shape,\n",
    "                                    border_mode='same',\n",
    "                                    init='he_normal'))\n",
    "            input_shape_specified = True\n",
    "        else:\n",
    "            model.add(Convolution2D(nums_feat_maps[conv_idx],\n",
    "                                    conv_sizes[conv_idx][0], conv_sizes[conv_idx][1],\n",
    "                                    border_mode='same',\n",
    "                                    init='he_normal'))\n",
    "        # add BN, Activation, pooling\n",
    "        model.add(BatchNormalization(axis=1, mode=2))\n",
    "        model.add(keras.layers.advanced_activations.ELU(alpha=1.0))  # TODO: select activation\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=pool_sizes[conv_idx]))\n",
    "        if conv_idx == conv_until:\n",
    "            break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "\n",
    "df_data = pd.read_csv(os.path.join(data_folder, \"train.csv\"), header=None)\n",
    "df_test = pd.read_csv(os.path.join(data_folder, \"test.csv\"), header=None)\n",
    "\n",
    "df_data.columns = [\"file\", \"genre_code\"]\n",
    "\n",
    "len_valid = int(len(df_data) * 0.1)\n",
    "df_train = df_data.loc[: len_valid]\n",
    "df_valid = df_data.loc[len_valid :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_model(mode, conv_until=None):\n",
    "    # setup stuff to build model\n",
    "\n",
    "    # This is it. use melgram, up to 6000 (SR is assumed to be 12000, see model.py),\n",
    "    # do decibel scaling\n",
    "    assert mode in ('feature', 'tagger')\n",
    "    if mode == 'feature':\n",
    "        last_layer = False\n",
    "    else:\n",
    "        last_layer = True\n",
    "\n",
    "    if conv_until is None:\n",
    "        conv_until = 4\n",
    "\n",
    "    assert K.image_dim_ordering() == 'th', ('image_dim_ordering should be \"th\". ' +\n",
    "                                            'open ~/.keras/keras.json to change it.')\n",
    "\n",
    "    args = Namespace(tf_type='melgram',  # which time-frequency to use\n",
    "                     normalize='no', decibel=True, fmin=0.0, fmax=6000,  # mel-spectrogram params\n",
    "                     n_mels=96, trainable_fb=False, trainable_kernel=False,  # mel-spectrogram params\n",
    "                     conv_until=conv_until)  # how many conv layer to use? set it 4 if tagging.\n",
    "    # set in [0, 1, 2, 3, 4] if feature extracting.\n",
    "\n",
    "    model = build_convnet_model(args=args, last_layer=last_layer)\n",
    "    model.load_weights('compact_cnn/weights_layer{}_{}.hdf5'.format(conv_until, K._backend),\n",
    "                       by_name=True)\n",
    "    # and use it!\n",
    "    return model\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    \n",
    "    Args:\n",
    "        base_model: keras model excluding top\n",
    "        nb_classes: # of classes\n",
    "        \n",
    "    Returns:\n",
    "        new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = base_model.output\n",
    "    predictions = Dense(10, activation='softmax')(x)\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model\n",
    "\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.savefig('accuracy.png')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.savefig('loss.png')\n",
    "    \n",
    "def load_audio(audio_path, save_path):\n",
    "    '''\n",
    "    Load audio\n",
    "    :param audio_path:\n",
    "    :return:\n",
    "    '''\n",
    "    # mel-spectrogram parameters\n",
    "    SR = 12000\n",
    "    DURA = 29  # to make it 1366 frame..\n",
    "\n",
    "    src, sr = librosa.load(audio_path, sr=SR)  # whole signal\n",
    "    n_sample = src.shape[0]\n",
    "    n_sample_fit = int(DURA*SR)\n",
    "\n",
    "    if n_sample < n_sample_fit:  # if too short\n",
    "        src = np.hstack((src, np.zeros((int(DURA*SR) - n_sample,))))\n",
    "    elif n_sample > n_sample_fit:  # if too long\n",
    "        src = src[(n_sample-n_sample_fit)/2:(n_sample+n_sample_fit)/2]\n",
    "    return src\n",
    "\n",
    "class DataGenerator(object):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, 1, 348000))\n",
    "        y = np.empty((self.batch_size, 10), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            # Store sample\n",
    "            X[i, 0,] = load_audio(os.path.join(\"../music_genre/train/\", ID), None)\n",
    "\n",
    "            # Store class\n",
    "            y_ = keras.utils.np_utils.to_categorical(self.labels[self.labels.file == ID].genre_code.values, nb_classes=10)\n",
    "            print(y_.shape)\n",
    "            y[i] = y_\n",
    "        print(y)\n",
    "        return X, y\n",
    "    \n",
    "    def get_data(self):\n",
    "        while True:\n",
    "            for i in range(self.__len__()): # 1875 * 32 = 60000 -> # of training samples\n",
    "                yield self.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    base_model = load_model(\"feature\", 3)\n",
    "    nb_classes = 10\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {'dim': (348000, 1),\n",
    "              'batch_size': 2,\n",
    "              'n_classes': 10,\n",
    "              'n_channels': 1,\n",
    "              'shuffle': True}\n",
    "\n",
    "    # Datasets\n",
    "    partition = df_train['file']\n",
    "    labels = df_train['genre_code']\n",
    "\n",
    "    # Generators\n",
    "    training_generator = DataGenerator(df_train['file'], df_train, **params)\n",
    "    validation_generator = DataGenerator(df_valid['file'], df_valid, **params)\n",
    "    model.summary()\n",
    "    history_tl = model.fit_generator(\n",
    "                                training_generator.get_data(),\n",
    "                                validation_data=validation_generator.get_data(),\n",
    "                                nb_val_samples=4,\n",
    "                                samples_per_epoch = 4, nb_epoch = 2,\n",
    "                                verbose=2) \n",
    "    \n",
    "    model.save(args.output_model_file)\n",
    "    if args.plot:\n",
    "        plot_training(history_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "melspectrogram_input_1 (InputLay (None, 1, 348000)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "melgram (Melspectrogram)         (None, 1, 96, 1360)   287840      melspectrogram_input_1[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "ConvBNEluDr (Sequential)         (None, 32, 4, 4)      28576       melgram[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_1 (Global (None, 32)            0           ConvBNEluDr[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            330         globalaveragepooling2d_1[0][0]   \n",
      "====================================================================================================\n",
      "Total params: 316,746\n",
      "Trainable params: 28,650\n",
      "Non-trainable params: 288,096\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "(1, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4dc2ba0c028a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7ac221718e20>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                                 \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0msamples_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                 verbose=2) \n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/PycharmProjects/MusicGenreClassification/venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "[[0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]]\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "[[0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4864815784918239474\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
